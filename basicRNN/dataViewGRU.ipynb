{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from basicRNN import *\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.spacing 4\n",
      "data.shape torch.Size([4992, 120, 50])\n",
      "labels.shape torch.Size([4992, 1])\n",
      "labels scales tensor([50.])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUgklEQVR4nO3df5Bd9Xnf8fenUiDGLkFUC1UkESmp/ENi7AY2KnHaDCntSDaJhVszXVIHjUOrCUNct9MmlpKp6UxGM2qTSVOaiowGU8TUg0bj2EYNxjUjx2GSAOpig0GAwsZyYY2C1qFNqNORI/npH/dg3yxX7N57d68Wzvs1s3PPec733PPsXemzZ8+Pe1NVSJLa4a+d6wYkSaNj6EtSixj6ktQihr4ktYihL0ktsvxcNzCXlStX1rp16851G5L0uvLoo49+o6rGZteXfOivW7eOycnJc92GJL2uJPlfveoe3pGkFjH0JalF5gz9JHcmOZnkyVn1Dyc5luRokv/QVd+VZKpZtqWrfmWSJ5pltyXJwn4rkqS5zGdP/y5ga3chyU8A24B3VtUm4Nea+kZgAtjUrLM3ybJmtduBHcCG5uuvPKckafHNGfpV9SDw0qzyzcCeqjrVjDnZ1LcBB6rqVFUdB6aAzUlWARdW1UPVebOfu4HrFuh7kCTN06DH9N8K/L0kjyT5vSQ/0tRXA893jZtuaqub6dn1npLsSDKZZHJmZmbAFiVJsw0a+suBFcBVwC8AB5tj9L2O09dr1Huqqn1VNV5V42Njr7rMVJI0oEFDfxr4VHUcAb4NrGzqa7vGrQFeaOpretQlSSM0aOh/Bvj7AEneCpwHfAM4BEwkOT/JejonbI9U1Qng5SRXNX8R3AjcO2zzkqT+zHlHbpJ7gKuBlUmmgVuBO4E7m8s4vwVsb07QHk1yEHgKOA3cUlVnmqe6mc6VQG8C7m++tIjW7bxvqPW/tufaBepE0lIxZ+hX1Q1nWfTBs4zfDezuUZ8ELu+rO0nSgvKOXElqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JapE5Qz/JnUlONh+NOHvZv0lSSVZ21XYlmUpyLMmWrvqVSZ5olt3WfFauJGmE5rOnfxewdXYxyVrgHwLPddU2AhPApmadvUmWNYtvB3bQ+bD0Db2eU5K0uOYM/ap6EHipx6L/CPwiUF21bcCBqjpVVceBKWBzklXAhVX1UPMB6ncD1w3bvCSpPwMd00/yPuDrVfX4rEWrgee75qeb2upmenb9bM+/I8lkksmZmZlBWpQk9dB36Ce5APhl4GO9Fveo1WvUe6qqfVU1XlXjY2Nj/bYoSTqL5QOs80PAeuDx5lzsGuBLSTbT2YNf2zV2DfBCU1/Toy5JGqG+9/Sr6omquqSq1lXVOjqBfkVV/QlwCJhIcn6S9XRO2B6pqhPAy0muaq7auRG4d+G+DUnSfMznks17gIeAtyWZTnLT2cZW1VHgIPAU8Dnglqo60yy+GbiDzsndPwbuH7J3SVKf5jy8U1U3zLF83az53cDuHuMmgcv77E+StIC8I1eSWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFpnPZ+TemeRkkie7ar+a5JkkX0ny6SQXdS3blWQqybEkW7rqVyZ5oll2W/MB6ZKkEZrPnv5dwNZZtQeAy6vqncAfAbsAkmwEJoBNzTp7kyxr1rkd2AFsaL5mP6ckaZHNGfpV9SDw0qza56vqdDP7MLCmmd4GHKiqU1V1HJgCNidZBVxYVQ9VVQF3A9ct0PcgSZqnhTim/7PA/c30auD5rmXTTW11Mz273lOSHUkmk0zOzMwsQIuSJBgy9JP8MnAa+MQrpR7D6jXqPVXVvqoar6rxsbGxYVqUJHVZPuiKSbYDPwlc0xyygc4e/NquYWuAF5r6mh51SdIIDbSnn2Qr8FHgfVX1F12LDgETSc5Psp7OCdsjVXUCeDnJVc1VOzcC9w7ZuySpT3Pu6Se5B7gaWJlkGriVztU65wMPNFdePlxVP1dVR5McBJ6ic9jnlqo60zzVzXSuBHoTnXMA9yNJGqk5Q7+qbuhR/vhrjN8N7O5RnwQu76s7SdKCGviYvrTY1u28b6j1v7bn2gXqRHrj8G0YJKlFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUW8I3cReUeppKXGPX1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWmTO0E9yZ5KTSZ7sql2c5IEkzzaPK7qW7UoyleRYki1d9SuTPNEsu635rFxJ0gjNZ0//LmDrrNpO4HBVbQAON/Mk2QhMAJuadfYmWdasczuwg86HpW/o8ZySpEU2Z+hX1YPAS7PK24D9zfR+4Lqu+oGqOlVVx4EpYHOSVcCFVfVQVRVwd9c6kqQRGfSY/qVVdQKgebykqa8Gnu8aN93UVjfTs+s9JdmRZDLJ5MzMzIAtSpJmW+gTub2O09dr1Huqqn1VNV5V42NjYwvWnCS13aCh/2JzyIbm8WRTnwbWdo1bA7zQ1Nf0qEuSRmjQ0D8EbG+mtwP3dtUnkpyfZD2dE7ZHmkNALye5qrlq58audSRJIzLnu2wmuQe4GliZZBq4FdgDHExyE/AccD1AVR1NchB4CjgN3FJVZ5qnupnOlUBvAu5vviRJIzRn6FfVDWdZdM1Zxu8GdveoTwKX99WdJGlBeUeuJLWIoS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLWLoS1KLGPqS1CKGviS1yFChn+RfJTma5Mkk9yT53iQXJ3kgybPN44qu8buSTCU5lmTL8O1LkvoxcOgnWQ38C2C8qi4HlgETwE7gcFVtAA438yTZ2CzfBGwF9iZZNlz7kqR+DHt4ZznwpiTLgQuAF4BtwP5m+X7gumZ6G3Cgqk5V1XFgCtg85PYlSX0YOPSr6uvArwHPASeAP6uqzwOXVtWJZswJ4JJmldXA811PMd3UXiXJjiSTSSZnZmYGbVGSNMswh3dW0Nl7Xw98P/DmJB98rVV61KrXwKraV1XjVTU+NjY2aIuSpFmGObzzD4DjVTVTVX8JfAp4N/BiklUAzePJZvw0sLZr/TV0DgdJkkZkmNB/DrgqyQVJAlwDPA0cArY3Y7YD9zbTh4CJJOcnWQ9sAI4MsX1JUp+WD7piVT2S5JPAl4DTwJeBfcBbgINJbqLzi+H6ZvzRJAeBp5rxt1TVmSH7lyT1YeDQB6iqW4FbZ5VP0dnr7zV+N7B7mG1KkgbnHbmS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktchQoZ/koiSfTPJMkqeT/GiSi5M8kOTZ5nFF1/hdSaaSHEuyZfj2JUn9GHZP/z8Bn6uqtwPvAp4GdgKHq2oDcLiZJ8lGYALYBGwF9iZZNuT2JUl9GDj0k1wI/DjwcYCq+lZV/R9gG7C/GbYfuK6Z3gYcqKpTVXUcmAI2D7p9SVL/htnT/0FgBvivSb6c5I4kbwYuraoTAM3jJc341cDzXetPN7VXSbIjyWSSyZmZmSFalCR1Gyb0lwNXALdX1Q8D36Q5lHMW6VGrXgOral9VjVfV+NjY2BAtSpK6LR9i3WlguqoeaeY/SSf0X0yyqqpOJFkFnOwav7Zr/TXAC0NsX1pU63beN9T6X9tz7QJ1Ii2cgff0q+pPgOeTvK0pXQM8BRwCtje17cC9zfQhYCLJ+UnWAxuAI4NuX5LUv2H29AE+DHwiyXnAV4EP0flFcjDJTcBzwPUAVXU0yUE6vxhOA7dU1Zkhty9J6sNQoV9VjwHjPRZdc5bxu4Hdw2xTkjQ478iVpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWGTr0kyxL8uUkv9PMX5zkgSTPNo8rusbuSjKV5FiSLcNuW5LUn4XY0/8I8HTX/E7gcFVtAA438yTZCEwAm4CtwN4kyxZg+5KkeRoq9JOsAa4F7ugqbwP2N9P7geu66geq6lRVHQemgM3DbF+S1J9h9/R/A/hF4NtdtUur6gRA83hJU18NPN81brqpvUqSHUkmk0zOzMwM2aIk6RUDh36SnwROVtWj812lR616DayqfVU1XlXjY2Njg7YoSZpl+RDr/hjwviTvBb4XuDDJfwNeTLKqqk4kWQWcbMZPA2u71l8DvDDE9iVJfRp4T7+qdlXVmqpaR+cE7Req6oPAIWB7M2w7cG8zfQiYSHJ+kvXABuDIwJ1Lkvo2zJ7+2ewBDia5CXgOuB6gqo4mOQg8BZwGbqmqM4uwfUnSWSxI6FfVF4EvNtN/ClxzlnG7gd0LsU1JUv+8I1eSWsTQl6QWWYxj+kvGup33DbX+1/Zcu0CdSNLS4J6+JLWIoS9JLWLoS1KLGPqS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLTJw6CdZm+R3kzyd5GiSjzT1i5M8kOTZ5nFF1zq7kkwlOZZky0J8A5Kk+RtmT/808K+r6h3AVcAtSTYCO4HDVbUBONzM0yybADYBW4G9SZYN07wkqT8Dh35VnaiqLzXTLwNPA6uBbcD+Zth+4LpmehtwoKpOVdVxYArYPOj2JUn9W5BPzkqyDvhh4BHg0qo6AZ1fDEkuaYatBh7uWm26qfV6vh3ADoDLLrtsIVqUXnf85DcthqFP5CZ5C/DbwL+sqj9/raE9atVrYFXtq6rxqhofGxsbtkVJUmOo0E/yPXQC/xNV9amm/GKSVc3yVcDJpj4NrO1afQ3wwjDblyT1Z5irdwJ8HHi6qn69a9EhYHszvR24t6s+keT8JOuBDcCRQbcvSerfMMf0fwz4GeCJJI81tV8C9gAHk9wEPAdcD1BVR5McBJ6ic+XPLVV1ZojtS5L6NHDoV9Xv0/s4PcA1Z1lnN7B70G1KkobjHbmS1CKGviS1iKEvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLWLoS1KLGPqS1CKGviS1yIJ8Rq4kzeZn/C5N7ulLUosY+pLUIoa+JLXIyEM/ydYkx5JMJdk56u1LUpuNNPSTLAP+C/AeYCNwQ5KNo+xBktps1FfvbAamquqrAEkOANuAp0bch6Q3OK8e6i1VNbqNJR8AtlbVP2vmfwb4O1X187PG7QB2NLNvA44NuMmVwDcGXHcx2Vd/7Ks/9tWfN2pfP1BVY7OLo97TT4/aq37rVNU+YN/QG0smq2p82OdZaPbVH/vqj331p219jfpE7jSwtmt+DfDCiHuQpNYadej/T2BDkvVJzgMmgEMj7kGSWmukh3eq6nSSnwf+B7AMuLOqji7iJoc+RLRI7Ks/9tUf++pPq/oa6YlcSdK55R25ktQihr4ktcgbIvTnemuHJP80yVearz9M8q4l0te2pqfHkkwm+btLoa+ucT+S5Exzf8U57yvJ1Un+rHm9HkvysaXQV1dvjyU5muT3lkJfSX6h67V6svlZXrwE+vq+JP89yePN6/Whxe5pnn2tSPLp5v/kkSSXj6CnO5OcTPLkWZYnyW1Nz19JcsXQG62q1/UXnRPCfwz8IHAe8DiwcdaYdwMrmun3AI8skb7ewnfPq7wTeGYp9NU17gvAZ4EPLIW+gKuB31mC/74uonNX+WXN/CVLoa9Z438K+MJS6Av4JeDfN9NjwEvAeUugr18Fbm2m3w4cHsHr9ePAFcCTZ1n+XuB+Ovc4XbUQ2fVG2NP/zls7VNW3gFfe2uE7quoPq+p/N7MP07k/YCn09X+r+ckCb6bHjWrnoq/Gh4HfBk6OoKd++hq1+fT108Cnquo5gKoaxWvW7+t1A3DPEumrgL+eJHR2fF4CTi+BvjYChwGq6hlgXZJLF7OpqnqQzvd/NtuAu6vjYeCiJKuG2eYbIfRXA893zU83tbO5ic5vzsU2r76SvD/JM8B9wM8uhb6SrAbeD/zWCPqZd1+NH20OC9yfZNMS6eutwIokX0zyaJIbl0hfACS5ANhK55f4UujrN4F30Lkx8wngI1X17SXQ1+PAPwJIshn4AUazg/ha+s23Ob0RQn9eb+0AkOQn6IT+Rxe1o2ZzPWq93nLi01X1duA64FcWuynm19dvAB+tqjOL3853zKevL9F5P5F3Af8Z+MxiN8X8+loOXAlcC2wB/m2Sty6Bvl7xU8AfVNVr7VEulPn0tQV4DPh+4G8Dv5nkwsVta1597aHzy/sxOn/pfpnF/wtkLv38nOfljfAZufN6a4ck7wTuAN5TVX+6VPp6RVU9mOSHkqysqsV886f59DUOHOj89c1K4L1JTlfVZ85lX1X1513Tn02yd4m8XtPAN6rqm8A3kzwIvAv4o3Pc1ysmGM2hHZhfXx8C9jSHNqeSHKdzDP3Iueyr+ff1IeicQAWON1/n0sK/dc1in6gYwYmQ5cBXgfV89wTNplljLgOmgHcvsb7+Ft89kXsF8PVX5s9lX7PG38VoTuTO5/X6m12v12bguaXwetE5VHG4GXsB8CRw+bnuqxn3fXSOGb95sX+GfbxetwP/rpm+tPl3v3IJ9HURzQll4J/TOZY+itdsHWc/kXstf/VE7pFht/e639Ovs7y1Q5Kfa5b/FvAx4G8Ae5u919O1yO+qN8++/jFwY5K/BP4f8E+q+Umf475Gbp59fQC4OclpOq/XxFJ4varq6SSfA74CfBu4o6p6XoI3yr6aoe8HPl+dv0IW3Tz7+hXgriRP0Amzj9bi/rU2377eAdyd5Aydq7FuWsyeAJLcQ+eqtJVJpoFbge/p6umzdK7gmQL+guYvkaG2ucj/ZyRJS8gb4USuJGmeDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWuT/A7IYcePkORQ5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels scales tensor([0.4286])\n",
      "train_dataset 3994\n",
      "test_dataset 998\n"
     ]
    }
   ],
   "source": [
    "ts = trainingService('paramsConfigGRU.yml')\n",
    "ts.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.setupModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]], Loss: 0.019710, , Loss Val: 0.013237\n",
      "Epoch [10/50]], Loss: 0.019388, , Loss Val: 0.016493\n",
      "Epoch [15/50]], Loss: 0.017326, , Loss Val: 0.017108\n",
      "Epoch [20/50]], Loss: 0.021349, , Loss Val: 0.013057\n",
      "Epoch [25/50]], Loss: 0.013827, , Loss Val: 0.014706\n",
      "Epoch [30/50]], Loss: 0.017105, , Loss Val: 0.015277\n",
      "Epoch [35/50]], Loss: 0.014731, , Loss Val: 0.015082\n",
      "Epoch [40/50]], Loss: 0.015010, , Loss Val: 0.024417\n",
      "Epoch [45/50]], Loss: 0.016464, , Loss Val: 0.013403\n",
      "Epoch [50/50]], Loss: 0.020399, , Loss Val: 0.020187\n",
      "Epoch [5/100]], Loss: 0.015938, , Loss Val: 0.012972\n",
      "Epoch [10/100]], Loss: 0.018004, , Loss Val: 0.009740\n",
      "Epoch [15/100]], Loss: 0.015795, , Loss Val: 0.015495\n",
      "Epoch [20/100]], Loss: 0.016230, , Loss Val: 0.012899\n",
      "Epoch [25/100]], Loss: 0.018301, , Loss Val: 0.019063\n",
      "Epoch [30/100]], Loss: 0.012496, , Loss Val: 0.019703\n",
      "Epoch [35/100]], Loss: 0.019277, , Loss Val: 0.015044\n",
      "Epoch [40/100]], Loss: 0.017166, , Loss Val: 0.018046\n",
      "Epoch [45/100]], Loss: 0.009969, , Loss Val: 0.015774\n",
      "Epoch [50/100]], Loss: 0.014852, , Loss Val: 0.014650\n",
      "Epoch [55/100]], Loss: 0.015816, , Loss Val: 0.010663\n",
      "Epoch [60/100]], Loss: 0.016422, , Loss Val: 0.014861\n",
      "Epoch [65/100]], Loss: 0.016717, , Loss Val: 0.012337\n",
      "Epoch [70/100]], Loss: 0.019609, , Loss Val: 0.016940\n",
      "Epoch [75/100]], Loss: 0.015403, , Loss Val: 0.015239\n",
      "Epoch [80/100]], Loss: 0.013662, , Loss Val: 0.021718\n",
      "Epoch [85/100]], Loss: 0.020314, , Loss Val: 0.015613\n",
      "Epoch [90/100]], Loss: 0.015093, , Loss Val: 0.013651\n",
      "Epoch [95/100]], Loss: 0.017970, , Loss Val: 0.014080\n",
      "Epoch [100/100]], Loss: 0.020434, , Loss Val: 0.018459\n",
      "Epoch [5/200]], Loss: 0.024419, , Loss Val: 0.017243\n",
      "Epoch [10/200]], Loss: 0.014678, , Loss Val: 0.017699\n",
      "Epoch [15/200]], Loss: 0.015011, , Loss Val: 0.022160\n",
      "Epoch [20/200]], Loss: 0.016674, , Loss Val: 0.014882\n",
      "Epoch [25/200]], Loss: 0.013448, , Loss Val: 0.017434\n",
      "Epoch [30/200]], Loss: 0.023283, , Loss Val: 0.014456\n",
      "Epoch [35/200]], Loss: 0.014090, , Loss Val: 0.013610\n",
      "Epoch [40/200]], Loss: 0.014670, , Loss Val: 0.012877\n",
      "Epoch [45/200]], Loss: 0.021721, , Loss Val: 0.016065\n",
      "Epoch [50/200]], Loss: 0.016699, , Loss Val: 0.015345\n",
      "Epoch [55/200]], Loss: 0.021717, , Loss Val: 0.015261\n",
      "Epoch [60/200]], Loss: 0.015599, , Loss Val: 0.015174\n",
      "Epoch [65/200]], Loss: 0.014422, , Loss Val: 0.021674\n",
      "Epoch [70/200]], Loss: 0.016185, , Loss Val: 0.010858\n",
      "Epoch [75/200]], Loss: 0.021206, , Loss Val: 0.013475\n",
      "Epoch [80/200]], Loss: 0.014623, , Loss Val: 0.016345\n",
      "Epoch [85/200]], Loss: 0.019383, , Loss Val: 0.022247\n",
      "Epoch [90/200]], Loss: 0.019722, , Loss Val: 0.011955\n",
      "Epoch [95/200]], Loss: 0.014198, , Loss Val: 0.024935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ts\u001b[38;5;241m.\u001b[39mtrainModel(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5e-3\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m ts\u001b[38;5;241m.\u001b[39mtrainModel(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5e-4\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m ts\u001b[38;5;241m.\u001b[39mtrainModel(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5e-5\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      4\u001b[0m ts\u001b[38;5;241m.\u001b[39mtrainModel(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5e-5\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5e-5\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[0;32m~/dev/ml4ao/basicRNN/basicRNN.py:321\u001b[0m, in \u001b[0;36mtrainingService.trainModel\u001b[0;34m(self, learning_rate, weight_decay, num_epochs)\u001b[0m\n\u001b[1;32m    319\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 321\u001b[0m     running_loss1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    322\u001b[0m running_loss1 \u001b[38;5;241m=\u001b[39m  running_loss1 \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader\u001b[38;5;241m.\u001b[39mtrain_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:        \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ts.trainModel(learning_rate=1e-3, weight_decay=0.5e-3, num_epochs=50)\n",
    "ts.trainModel(learning_rate=1e-4, weight_decay=0.5e-4, num_epochs=100)\n",
    "ts.trainModel(learning_rate=1e-5, weight_decay=0.5e-5, num_epochs=200)\n",
    "ts.trainModel(learning_rate=0.5e-5, weight_decay=0.5e-5, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.model.eval()\n",
    "test_errors = []\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "running_loss1 = 0.0\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for i, (inputsT, labelsT) in enumerate(ts.test_loader):\n",
    "        inputsT = inputsT.to(device)\n",
    "        labelsT = labelsT.to(device)\n",
    "        outputsT = ts.model(inputsT)\n",
    "        errorsT = outputsT - labelsT        \n",
    "        test_errors.extend(errorsT.cpu().numpy())\n",
    "        test_labels.extend(labelsT.view(-1).tolist())\n",
    "        test_predictions.extend(outputsT.view(-1).tolist())\n",
    "        lossV = ts.criterion(outputsT, labelsT)\n",
    "        running_loss1 += lossV.cpu().item()\n",
    "\n",
    "train_errors = []\n",
    "train_labels = []\n",
    "train_predictions = []\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for i, (inputs, labels) in enumerate(ts.train_loader):\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        outputs = ts.model(inputs)\n",
    "        # Compute the error for each sample\n",
    "        errors = outputs - labels\n",
    "        train_errors.extend(errors.view(-1).tolist())\n",
    "        train_labels.extend(labels.view(-1).tolist())\n",
    "        train_predictions.extend(outputs.view(-1).tolist())\n",
    "        if i==0:\n",
    "            pp = inputs[1].cpu().numpy()\n",
    "            plt.plot(pp)\n",
    "            plt.show()\n",
    "\n",
    "#plt.plot(test_errors1)\n",
    "#plt.plot(train_errors)\n",
    "#plt.show()\n",
    "test_labels = np.array(test_labels)\n",
    "train_labels = np.array(train_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "train_predictions = np.array(train_predictions)\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.scatter(train_labels, train_predictions)\n",
    "\n",
    "plt.scatter(test_labels, test_labels)\n",
    "\n",
    "test_abs_errors = np.abs(test_errors)\n",
    "train_abs_errors = np.abs(train_errors)\n",
    "print(\"Mean/Median Absolute error TEST:\", np.mean(test_abs_errors), np.median(test_abs_errors))\n",
    "print(\"Mean/Median Absolute error TRAIN:\", np.mean(train_abs_errors), np.median(train_abs_errors))\n",
    "\n",
    "print(\"R^2\", 1-np.mean(np.square(test_abs_errors))/np.var(test_labels))\n",
    "\n",
    "test_labels[test_labels == 0.0] = 1\n",
    "train_labels[train_labels == 0.0] = 1\n",
    "print(\"Mean Relative error TEST:\", np.mean(np.abs(test_errors)/np.abs(test_labels)))\n",
    "print(\"Mean Relative error TRAIN:\", np.mean(np.abs(train_errors)/np.abs(train_labels)))\n",
    "#plt.ylim(0, 1)\n",
    "#plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#ts.criterion = nn.MSELoss(reduction='none')  # Set reduction='none' to get individual errors\n",
    "test_errors, test_labels, test_predictions = ts.testModel()\n",
    "plt.plot(test_errors)\n",
    "plt.show()\n",
    "print(np.mean(np.abs(test_errors)))\n",
    "plt.scatter(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.std_mean(ts.data_loader.labels) )\n",
    "olStd, olMean  = torch.std_mean(ts.data_loader.data, dim=1 )\n",
    "#print( ts.data_loader.labels )\n",
    "#print( olMean )\n",
    "#print( olStd )\n",
    "print( olMean.shape, olStd.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = 20\n",
    "t = torch.tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
    "hist = torch.histc(ts.data_loader.labels, bins=bins, min=0, max=2)\n",
    "x = range(bins)\n",
    "plt.bar(x, hist, align='center')\n",
    "plt.xlabel('Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ts.data_loader.labels.shape )\n",
    "print( olMean[:,0].shape)\n",
    "#print( olStd )\n",
    "#plt.scatter(torch.sqrt(torch.sum(torch.square(olMean), axis=1)), ts.data_loader.labels )\n",
    "plt.scatter(torch.sum(torch.square(olStd), axis=1), ts.data_loader.labels, s=4 )\n",
    "plt.ylim(0, 2.)\n",
    "plt.xlim(0, 2000*1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( olStd )\n",
    "olStd[390,:] = 0\n",
    "\n",
    "plt.plot(olStd[:,0])\n",
    "plt.plot(olStd[:,1])\n",
    "plt.plot(olStd[:,2])\n",
    "plt.plot(olStd[:,3])\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "alldata = ts.data_loader.data.numpy()\n",
    "print(alldata.shape)\n",
    "red1 = np.sqrt(np.sum(np.square(ts.data_loader.data.numpy()), axis=1))\n",
    "print(red1.shape)\n",
    "pp_sum = np.mean(red1, axis=0)\n",
    "print(pp_sum.shape)\n",
    "plt.plot(np.log(pp_sum))\n",
    "plt.show()\n",
    "\n",
    "for ii in range(0,10,1):\n",
    "    pp = ts.data_loader.data[77, :, ii].numpy()\n",
    "    plt.plot(pp)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#for ii in range(10):\n",
    "#    plt.plot(torch.sqrt(torch.sum(torch.square(ts.data_loader.data[ii, :, :]), axis=1)))\n",
    "#    plt.axhline(y=ts.data_loader.labels[ii].data*1e3, color='r', linestyle='-')\n",
    "#    plt.show()\n",
    "\n",
    "#plt.plot(ts.data_loader.data[77, :, 4])\n",
    "#plt.plot(ts.data_loader.data[77, :, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
