{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from basicRNN import *\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.spacing 1\n",
      "data.shape torch.Size([4992, 100])\n",
      "labels.shape torch.Size([4992, 1])\n",
      "labels scales tensor([0.9581])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels scales tensor([0.8363])\n",
      "train_dataset 3994\n",
      "test_dataset 998\n"
     ]
    }
   ],
   "source": [
    "ts = trainingService('paramsConfigMLP4.yml')\n",
    "ts.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.setupModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]], Loss: 0.000723, , Loss Val: 0.001649\n",
      "Epoch [10/50]], Loss: 0.002548, , Loss Val: 0.001865\n",
      "Epoch [15/50]], Loss: 0.000980, , Loss Val: 0.000465\n",
      "Epoch [20/50]], Loss: 0.002153, , Loss Val: 0.000994\n",
      "Epoch [25/50]], Loss: 0.000831, , Loss Val: 0.002148\n",
      "Epoch [30/50]], Loss: 0.001504, , Loss Val: 0.002014\n",
      "Epoch [35/50]], Loss: 0.000915, , Loss Val: 0.001395\n",
      "Epoch [40/50]], Loss: 0.000812, , Loss Val: 0.000998\n",
      "Epoch [45/50]], Loss: 0.001735, , Loss Val: 0.001248\n",
      "Epoch [50/50]], Loss: 0.000763, , Loss Val: 0.001636\n",
      "Epoch [5/100]], Loss: 0.000960, , Loss Val: 0.001428\n",
      "Epoch [10/100]], Loss: 0.000647, , Loss Val: 0.000649\n",
      "Epoch [15/100]], Loss: 0.000674, , Loss Val: 0.000952\n",
      "Epoch [20/100]], Loss: 0.000607, , Loss Val: 0.000975\n",
      "Epoch [25/100]], Loss: 0.001302, , Loss Val: 0.000631\n",
      "Epoch [30/100]], Loss: 0.000286, , Loss Val: 0.000618\n",
      "Epoch [35/100]], Loss: 0.000755, , Loss Val: 0.000786\n",
      "Epoch [40/100]], Loss: 0.001044, , Loss Val: 0.000852\n",
      "Epoch [45/100]], Loss: 0.001041, , Loss Val: 0.001179\n",
      "Epoch [50/100]], Loss: 0.000294, , Loss Val: 0.000456\n",
      "Epoch [55/100]], Loss: 0.000848, , Loss Val: 0.001177\n",
      "Epoch [60/100]], Loss: 0.001063, , Loss Val: 0.000453\n",
      "Epoch [65/100]], Loss: 0.000784, , Loss Val: 0.000370\n",
      "Epoch [70/100]], Loss: 0.000564, , Loss Val: 0.000622\n",
      "Epoch [75/100]], Loss: 0.001254, , Loss Val: 0.001547\n",
      "Epoch [80/100]], Loss: 0.000588, , Loss Val: 0.001404\n",
      "Epoch [85/100]], Loss: 0.000529, , Loss Val: 0.001120\n",
      "Epoch [90/100]], Loss: 0.001059, , Loss Val: 0.001501\n",
      "Epoch [95/100]], Loss: 0.001112, , Loss Val: 0.000596\n",
      "Epoch [100/100]], Loss: 0.001050, , Loss Val: 0.000307\n",
      "Epoch [5/200]], Loss: 0.000489, , Loss Val: 0.000613\n",
      "Epoch [10/200]], Loss: 0.001264, , Loss Val: 0.000659\n",
      "Epoch [15/200]], Loss: 0.000553, , Loss Val: 0.000470\n",
      "Epoch [20/200]], Loss: 0.000591, , Loss Val: 0.003042\n",
      "Epoch [25/200]], Loss: 0.000893, , Loss Val: 0.000883\n",
      "Epoch [30/200]], Loss: 0.001353, , Loss Val: 0.000791\n",
      "Epoch [35/200]], Loss: 0.001533, , Loss Val: 0.001256\n",
      "Epoch [40/200]], Loss: 0.001576, , Loss Val: 0.000447\n",
      "Epoch [45/200]], Loss: 0.000471, , Loss Val: 0.001447\n",
      "Epoch [50/200]], Loss: 0.000876, , Loss Val: 0.000659\n",
      "Epoch [55/200]], Loss: 0.000196, , Loss Val: 0.001161\n",
      "Epoch [60/200]], Loss: 0.000340, , Loss Val: 0.000396\n",
      "Epoch [65/200]], Loss: 0.000783, , Loss Val: 0.000272\n",
      "Epoch [70/200]], Loss: 0.000421, , Loss Val: 0.000314\n",
      "Epoch [75/200]], Loss: 0.000558, , Loss Val: 0.000215\n",
      "Epoch [80/200]], Loss: 0.000886, , Loss Val: 0.000437\n",
      "Epoch [85/200]], Loss: 0.000618, , Loss Val: 0.000288\n",
      "Epoch [90/200]], Loss: 0.000880, , Loss Val: 0.000737\n",
      "Epoch [95/200]], Loss: 0.001540, , Loss Val: 0.000566\n",
      "Epoch [100/200]], Loss: 0.000250, , Loss Val: 0.001416\n",
      "Epoch [105/200]], Loss: 0.000731, , Loss Val: 0.000701\n",
      "Epoch [110/200]], Loss: 0.001218, , Loss Val: 0.000821\n",
      "Epoch [115/200]], Loss: 0.001894, , Loss Val: 0.000400\n",
      "Epoch [120/200]], Loss: 0.001388, , Loss Val: 0.000306\n",
      "Epoch [125/200]], Loss: 0.000771, , Loss Val: 0.000400\n",
      "Epoch [130/200]], Loss: 0.002245, , Loss Val: 0.000637\n",
      "Epoch [135/200]], Loss: 0.000349, , Loss Val: 0.000696\n",
      "Epoch [140/200]], Loss: 0.001221, , Loss Val: 0.001103\n",
      "Epoch [145/200]], Loss: 0.001202, , Loss Val: 0.000526\n",
      "Epoch [150/200]], Loss: 0.000806, , Loss Val: 0.000478\n",
      "Epoch [155/200]], Loss: 0.000728, , Loss Val: 0.000618\n",
      "Epoch [160/200]], Loss: 0.000401, , Loss Val: 0.001432\n",
      "Epoch [165/200]], Loss: 0.000558, , Loss Val: 0.000834\n",
      "Epoch [170/200]], Loss: 0.000706, , Loss Val: 0.001146\n",
      "Epoch [175/200]], Loss: 0.000650, , Loss Val: 0.000549\n",
      "Epoch [180/200]], Loss: 0.000417, , Loss Val: 0.000794\n",
      "Epoch [185/200]], Loss: 0.000444, , Loss Val: 0.000667\n",
      "Epoch [190/200]], Loss: 0.000511, , Loss Val: 0.002007\n",
      "Epoch [195/200]], Loss: 0.000278, , Loss Val: 0.000230\n",
      "Epoch [200/200]], Loss: 0.000568, , Loss Val: 0.001585\n",
      "Epoch [5/400]], Loss: 0.000312, , Loss Val: 0.000349\n",
      "Epoch [10/400]], Loss: 0.000461, , Loss Val: 0.001814\n",
      "Epoch [15/400]], Loss: 0.000555, , Loss Val: 0.000415\n",
      "Epoch [20/400]], Loss: 0.000557, , Loss Val: 0.001438\n",
      "Epoch [25/400]], Loss: 0.000752, , Loss Val: 0.000925\n",
      "Epoch [30/400]], Loss: 0.000141, , Loss Val: 0.001739\n",
      "Epoch [35/400]], Loss: 0.000376, , Loss Val: 0.000577\n",
      "Epoch [40/400]], Loss: 0.000447, , Loss Val: 0.000489\n",
      "Epoch [45/400]], Loss: 0.000486, , Loss Val: 0.000442\n",
      "Epoch [50/400]], Loss: 0.000786, , Loss Val: 0.002228\n",
      "Epoch [55/400]], Loss: 0.000589, , Loss Val: 0.000758\n",
      "Epoch [60/400]], Loss: 0.000381, , Loss Val: 0.000903\n",
      "Epoch [65/400]], Loss: 0.001421, , Loss Val: 0.001367\n",
      "Epoch [70/400]], Loss: 0.000613, , Loss Val: 0.000673\n",
      "Epoch [75/400]], Loss: 0.000438, , Loss Val: 0.001372\n",
      "Epoch [80/400]], Loss: 0.000451, , Loss Val: 0.000455\n",
      "Epoch [85/400]], Loss: 0.000634, , Loss Val: 0.001290\n",
      "Epoch [90/400]], Loss: 0.000373, , Loss Val: 0.002324\n",
      "Epoch [95/400]], Loss: 0.000800, , Loss Val: 0.000413\n",
      "Epoch [100/400]], Loss: 0.000511, , Loss Val: 0.000433\n",
      "Epoch [105/400]], Loss: 0.000858, , Loss Val: 0.000453\n",
      "Epoch [110/400]], Loss: 0.000359, , Loss Val: 0.000764\n",
      "Epoch [115/400]], Loss: 0.001304, , Loss Val: 0.001626\n",
      "Epoch [120/400]], Loss: 0.001936, , Loss Val: 0.001357\n",
      "Epoch [125/400]], Loss: 0.001055, , Loss Val: 0.001017\n",
      "Epoch [130/400]], Loss: 0.000812, , Loss Val: 0.000843\n",
      "Epoch [135/400]], Loss: 0.000814, , Loss Val: 0.001064\n",
      "Epoch [140/400]], Loss: 0.001578, , Loss Val: 0.000939\n",
      "Epoch [145/400]], Loss: 0.001130, , Loss Val: 0.000294\n",
      "Epoch [150/400]], Loss: 0.001221, , Loss Val: 0.000628\n",
      "Epoch [155/400]], Loss: 0.000522, , Loss Val: 0.001293\n",
      "Epoch [160/400]], Loss: 0.000562, , Loss Val: 0.002969\n"
     ]
    }
   ],
   "source": [
    "ts.trainModel(learning_rate=1e-3, num_epochs=50)\n",
    "ts.trainModel(learning_rate=1e-4, num_epochs=100)\n",
    "ts.trainModel(learning_rate=1e-5, num_epochs=200)\n",
    "ts.trainModel(learning_rate=1e-6, num_epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_ind in range(3):\n",
    "\n",
    "    ts.model.eval()\n",
    "    test_errors = []\n",
    "    test_labels = []\n",
    "    test_predictions = []\n",
    "\n",
    "    running_loss1 = 0.0\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for i, (inputsT, labelsT) in enumerate(ts.test_loader):\n",
    "            inputsT = inputsT.to(device)\n",
    "            labelsT = labelsT.to(device)[:,l_ind]\n",
    "            outputsT = ts.model(inputsT)[:,l_ind]\n",
    "            errorsT = outputsT - labelsT\n",
    "            test_errors.extend(errorsT.cpu().numpy())\n",
    "            test_labels.extend(labelsT.view(-1).tolist())\n",
    "            test_predictions.extend(outputsT.view(-1).tolist())\n",
    "            lossV = ts.criterion(outputsT, labelsT)\n",
    "            running_loss1 += lossV.cpu().item()\n",
    "\n",
    "    train_errors = []\n",
    "    train_labels = []\n",
    "    train_predictions = []\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for i, (inputs, labels) in enumerate(ts.train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)[:,l_ind]\n",
    "            outputs = ts.model(inputs)[:,l_ind]\n",
    "            # Compute the error for each sample\n",
    "            errors = outputs - labels\n",
    "            train_errors.extend(errors.view(-1).tolist())\n",
    "            train_labels.extend(labels.view(-1).tolist())\n",
    "            train_predictions.extend(outputs.view(-1).tolist())\n",
    "            if i==0:\n",
    "                pp = inputs[1].cpu().numpy()\n",
    "                plt.plot(pp)\n",
    "                plt.show()\n",
    "\n",
    "    #plt.plot(test_errors1)\n",
    "    #plt.plot(train_errors)\n",
    "    #plt.show()\n",
    "    test_labels = np.array(test_labels)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_predictions = np.array(test_predictions)\n",
    "    train_predictions = np.array(train_predictions)\n",
    "\n",
    "    plt.scatter(test_labels, test_predictions)\n",
    "    plt.scatter(train_labels, train_predictions)\n",
    "\n",
    "    plt.scatter(test_labels, test_labels)\n",
    "\n",
    "    test_abs_errors = np.abs(test_errors)\n",
    "    train_abs_errors = np.abs(train_errors)\n",
    "    print(\"Mean/Median Absolute error TEST:\", np.mean(test_abs_errors), np.median(test_abs_errors))\n",
    "    print(\"Mean/Median Absolute error TRAIN:\", np.mean(train_abs_errors), np.median(train_abs_errors))\n",
    "\n",
    "    print(\"R^2\", 1-np.mean(np.square(test_abs_errors))/np.var(test_labels))\n",
    "\n",
    "    test_labels[test_labels == 0.0] = 1\n",
    "    train_labels[train_labels == 0.0] = 1\n",
    "    print(\"Mean/Median Relative error TEST:\", np.mean(np.abs(test_errors)/np.abs(test_labels)), np.median(np.abs(test_errors)/np.abs(test_labels)))\n",
    "    print(\"Mean/Median Relative error TRAIN:\", np.mean(np.abs(train_errors)/np.abs(train_labels)), np.median(np.abs(train_errors)/np.abs(train_labels)))\n",
    "    #plt.ylim(0, 1)\n",
    "    #plt.xlim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#ts.criterion = nn.MSELoss(reduction='none')  # Set reduction='none' to get individual errors\n",
    "test_errors, test_labels, test_predictions = ts.testModel()\n",
    "plt.plot(test_errors)\n",
    "plt.show()\n",
    "print(np.mean(np.abs(test_errors)))\n",
    "plt.scatter(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.std_mean(ts.data_loader.labels) )\n",
    "olStd, olMean  = torch.std_mean(ts.data_loader.data, dim=1 )\n",
    "#print( ts.data_loader.labels )\n",
    "#print( olMean )\n",
    "#print( olStd )\n",
    "print( olMean.shape, olStd.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = 20\n",
    "t = torch.tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
    "hist = torch.histc(ts.data_loader.labels, bins=bins, min=0, max=2)\n",
    "x = range(bins)\n",
    "plt.bar(x, hist, align='center')\n",
    "plt.xlabel('Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ts.data_loader.labels.shape )\n",
    "print( olMean[:,0].shape)\n",
    "#print( olStd )\n",
    "#plt.scatter(torch.sqrt(torch.sum(torch.square(olMean), axis=1)), ts.data_loader.labels )\n",
    "plt.scatter(torch.sum(torch.square(olStd), axis=1), ts.data_loader.labels, s=4 )\n",
    "plt.ylim(0, 2.)\n",
    "plt.xlim(0, 2000*1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( olStd )\n",
    "olStd[390,:] = 0\n",
    "\n",
    "plt.plot(olStd[:,0])\n",
    "plt.plot(olStd[:,1])\n",
    "plt.plot(olStd[:,2])\n",
    "plt.plot(olStd[:,3])\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "alldata = ts.data_loader.data.numpy()\n",
    "print(alldata.shape)\n",
    "red1 = np.sqrt(np.sum(np.square(ts.data_loader.data.numpy()), axis=1))\n",
    "print(red1.shape)\n",
    "pp_sum = np.mean(red1, axis=0)\n",
    "print(pp_sum.shape)\n",
    "plt.plot(np.log(pp_sum))\n",
    "plt.show()\n",
    "\n",
    "for ii in range(0,10,1):\n",
    "    pp = ts.data_loader.data[77, :, ii].numpy()\n",
    "    plt.plot(pp)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#for ii in range(10):\n",
    "#    plt.plot(torch.sqrt(torch.sum(torch.square(ts.data_loader.data[ii, :, :]), axis=1)))\n",
    "#    plt.axhline(y=ts.data_loader.labels[ii].data*1e3, color='r', linestyle='-')\n",
    "#    plt.show()\n",
    "\n",
    "#plt.plot(ts.data_loader.data[77, :, 4])\n",
    "#plt.plot(ts.data_loader.data[77, :, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
